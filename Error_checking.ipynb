{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa3c725-2802-4b97-8da2-a941be15a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\keert\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\keert\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\keert\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\keert\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\keert\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\keert\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: C:\\Users\\keert\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182a4c5d-f97d-48cf-9882-af3518b70d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id     item_id  rating\n",
      "0      101  Item_101_1     4.6\n",
      "1      101  Item_101_2     4.6\n",
      "2      101  Item_101_3     4.6\n",
      "3      101  Item_101_4     4.6\n",
      "4      101  Item_101_5     4.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a Pandas DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\keert\\OneDrive\\Desktop\\Shopping_Deals_Recommeneder\\dataset\\user_item_ratings.csv')\n",
    "\n",
    "# Check the first few rows to understand the data structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5df87d-2ad8-4e33-88fc-f4b27fa65afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    0\n",
      "item_id    0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "print(df.isnull().sum())  # This shows the count of missing values in each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585b6c37-956d-47f7-90c2-f833be4ded5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id      int64\n",
      "item_id     object\n",
      "rating     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of each column\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f360e6a-b5f1-421e-a271-a89eb35d3da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id     object\n",
      "item_id     object\n",
      "rating     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert 'user_id' and 'item_id' to string (if they aren't already)\n",
    "df['user_id'] = df['user_id'].astype(str)\n",
    "df['item_id'] = df['item_id'].astype(str)\n",
    "\n",
    "# Convert 'rating' to float (if it isn't already)\n",
    "df['rating'] = df['rating'].astype(float)\n",
    "\n",
    "# Check the data types again to ensure they've been updated\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd0e4a5a-9e1d-4f80-8e43-a534935dfc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id  Item_101_1  Item_101_10  Item_101_11  Item_101_12  Item_101_13  \\\n",
      "user_id                                                                   \n",
      "101             4.6          4.6          4.6          4.6          4.6   \n",
      "102             NaN          NaN          NaN          NaN          NaN   \n",
      "103             NaN          NaN          NaN          NaN          NaN   \n",
      "104             NaN          NaN          NaN          NaN          NaN   \n",
      "105             NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "item_id  Item_101_14  Item_101_2  Item_101_3  Item_101_4  Item_101_5  ...  \\\n",
      "user_id                                                               ...   \n",
      "101              4.6         4.6         4.6         4.6         4.6  ...   \n",
      "102              NaN         NaN         NaN         NaN         NaN  ...   \n",
      "103              NaN         NaN         NaN         NaN         NaN  ...   \n",
      "104              NaN         NaN         NaN         NaN         NaN  ...   \n",
      "105              NaN         NaN         NaN         NaN         NaN  ...   \n",
      "\n",
      "item_id  Item_450_1  Item_450_10  Item_450_2  Item_450_3  Item_450_4  \\\n",
      "user_id                                                                \n",
      "101             NaN          NaN         NaN         NaN         NaN   \n",
      "102             NaN          NaN         NaN         NaN         NaN   \n",
      "103             NaN          NaN         NaN         NaN         NaN   \n",
      "104             NaN          NaN         NaN         NaN         NaN   \n",
      "105             NaN          NaN         NaN         NaN         NaN   \n",
      "\n",
      "item_id  Item_450_5  Item_450_6  Item_450_7  Item_450_8  Item_450_9  \n",
      "user_id                                                              \n",
      "101             NaN         NaN         NaN         NaN         NaN  \n",
      "102             NaN         NaN         NaN         NaN         NaN  \n",
      "103             NaN         NaN         NaN         NaN         NaN  \n",
      "104             NaN         NaN         NaN         NaN         NaN  \n",
      "105             NaN         NaN         NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 4410 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a user-item matrix (pivot table)\n",
    "user_item_matrix = df.pivot(index='user_id', columns='item_id', values='rating')\n",
    "\n",
    "# Display the user-item matrix\n",
    "print(user_item_matrix.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b61c3a4-1bed-4b03-8cad-01a91faa6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = user_item_matrix.fillna(user_item_matrix.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96f4cba-b4d2-4759-b7c6-779330e9152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = user_item_matrix.stack().mean()\n",
    "user_item_matrix = user_item_matrix.fillna(global_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb5268fa-4e37-4313-9a31-84acbb870657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2794\n",
      "RMSE: 0.2794477251423484\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))  # Assuming ratings are between 1 and 5\n",
    "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Split the data into train and test sets (80% training, 20% testing)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Initialize the SVD model\n",
    "svd = SVD()\n",
    "\n",
    "# Train the model on the training set\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Evaluate the model using RMSE (Root Mean Squared Error)\n",
    "predictions = svd.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e527b1e4-490b-4b55-a3a4-5dc70ec9da5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID 107 exists in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ratings data\n",
    "ratings_data_path = \"user_item_ratings.csv\"  # Replace with your actual path\n",
    "ratings_df = pd.read_csv(ratings_data_path)\n",
    "\n",
    "# Check if the user_id exists in the dataset\n",
    "user_id_to_check = 107  # Replace with the user_id you want to check\n",
    "\n",
    "# Check if the user_id exists in the 'user_id' column\n",
    "user_exists = ratings_df['user_id'].isin([user_id_to_check]).any()\n",
    "\n",
    "if user_exists:\n",
    "    print(f\"User ID {user_id_to_check} exists in the dataset.\")\n",
    "else:\n",
    "    print(f\"User ID {user_id_to_check} does NOT exist in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4188dd00-20cd-4119-9273-75d11f5b42e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check if the user exists in the model's internal mapping\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(user_id_to_check) \u001b[38;5;129;01min\u001b[39;00m recommender\u001b[38;5;241m.\u001b[39mtrainset\u001b[38;5;241m.\u001b[39m_raw2inner_id_users:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m exists in the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms internal mapping.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recommender' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if the user exists in the model's internal mapping\n",
    "if str(user_id_to_check) in recommender.trainset._raw2inner_id_users:\n",
    "    print(f\"User ID {user_id_to_check} exists in the model's internal mapping.\")\n",
    "else:\n",
    "    print(f\"User ID {user_id_to_check} does NOT exist in the model's internal mapping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a7f7487-82d9-439e-9ba2-e4c30ad21d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id      item_id  rating\n",
      "74      107   Item_107_1     4.5\n",
      "75      107   Item_107_2     4.5\n",
      "76      107   Item_107_3     4.5\n",
      "77      107   Item_107_4     4.5\n",
      "78      107   Item_107_5     4.5\n",
      "79      107   Item_107_6     4.5\n",
      "80      107   Item_107_7     4.5\n",
      "81      107   Item_107_8     4.5\n",
      "82      107   Item_107_9     4.5\n",
      "83      107  Item_107_10     4.5\n",
      "84      107  Item_107_11     4.5\n",
      "85      107  Item_107_12     4.5\n",
      "86      107  Item_107_13     4.5\n",
      "87      107  Item_107_14     4.5\n",
      "88      107  Item_107_15     4.5\n"
     ]
    }
   ],
   "source": [
    "user_ratings = ratings_df[ratings_df['user_id'] == user_id_to_check]\n",
    "print(user_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b5db66-20b0-4443-bc27-2c4bf441b94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID 107 does NOT exist in the model's training data.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained collaborative filtering model\n",
    "model = joblib.load('collaborative_model.pkl')\n",
    "\n",
    "# Access the trainset from the model\n",
    "trainset = model.trainset\n",
    "\n",
    "# Check if User ID 107 exists in the raw-to-internal user ID mapping\n",
    "user_id = 107\n",
    "\n",
    "# Check if the user_id exists in the model's internal training data\n",
    "if str(user_id) in trainset._raw2inner_id_users:\n",
    "    print(f\"User ID {user_id} exists in the model's training data!\")\n",
    "else:\n",
    "    print(f\"User ID {user_id} does NOT exist in the model's training data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d515ba25-682e-42e6-b672-83caf31bdf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs in the model's training data:\n",
      "[101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained collaborative filtering model\n",
    "model = joblib.load('collaborative_model.pkl')\n",
    "\n",
    "# Access the trainset from the model\n",
    "trainset = model.trainset\n",
    "\n",
    "# Get all the raw user IDs that were present in the training data\n",
    "raw_user_ids = list(trainset._raw2inner_id_users.keys())\n",
    "\n",
    "# Print the list of raw user IDs\n",
    "print(\"User IDs in the model's training data:\")\n",
    "print(raw_user_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbfc8002-b7b5-4a1b-9b0d-70848fcbd6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID 107 does NOT exist in the model's training data.\n"
     ]
    }
   ],
   "source": [
    "user_id = 107\n",
    "if str(user_id) in raw_user_ids:\n",
    "    print(f\"User ID {user_id} exists in the model's training data.\")\n",
    "else:\n",
    "    print(f\"User ID {user_id} does NOT exist in the model's training data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05affab4-8f64-41bf-8557-3b2f5a35bdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collaborative_model_updated.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load the complete dataset\n",
    "data = Dataset.load_from_df(ratings_df[['user_id', 'item_id', 'rating']], Reader(rating_scale=(1, 5)))\n",
    "\n",
    "# Train-test split (optional, for validation)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Initialize and train the model\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'collaborative_model_updated.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57d4ac42-3e2f-4b21-a76d-b329565a47a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_top_rated_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_recommendations(internal_user_id)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Fallback: Recommend top-rated items\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m get_top_rated_items(ratings_df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_top_rated_items' is not defined"
     ]
    }
   ],
   "source": [
    "if str(user_id) in raw_user_ids:\n",
    "    internal_user_id = trainset._raw2inner_id_users[str(user_id)]\n",
    "    recommendations = model.get_recommendations(internal_user_id)\n",
    "else:\n",
    "    # Fallback: Recommend top-rated items\n",
    "    recommendations = get_top_rated_items(ratings_df)  # Implement this function based on ratings_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7d44c-c08c-447f-8f6d-798a04d88879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
